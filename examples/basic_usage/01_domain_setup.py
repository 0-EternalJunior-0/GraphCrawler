"""Basic Example 4: Different API Levels

–¶–µ–π –ø—Ä–∏–∫–ª–∞–¥ –ø–æ–∫–∞–∑—É—î –¢–†–ò —Ä—ñ–≤–Ω—ñ API –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ GraphCrawler:
- Level 1: –ü—Ä–æ—Å—Ç–∏–π crawl() - –Ω–∞–π–ø—Ä–æ—Å—Ç—ñ—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
- Level 2: GraphCrawler –∫–ª–∞—Å - –±—ñ–ª—å—à–µ –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π
- Level 3: ApplicationContainer - –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å

–í–∏ –Ω–∞–≤—á–∏—Ç–µ—Å—è:
- –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —è–∫–∏–π —Ä—ñ–≤–µ–Ω—å API
- –†—ñ–∑–Ω–∏—Ü—è –º—ñ–∂ –ø—ñ–¥—Ö–æ–¥–∞–º–∏
- –ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ –∫–æ–∂–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è
- –Ø–∫ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–∏ –≤—ñ–¥ –ø—Ä–æ—Å—Ç–æ–≥–æ –¥–æ —Å–∫–ª–∞–¥–Ω–æ–≥–æ

–°–∞–π—Ç –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è: https://www.royalroad.com/
"""

import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def level_1_simple_crawl():
    """Level 1: –ù–∞–π–ø—Ä–æ—Å—Ç—ñ—à–∏–π —Å–ø–æ—Å—ñ–± - –æ–¥–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è crawl()

    –ü–µ—Ä–µ–≤–∞–≥–∏:
    - –û–¥–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è - –ø—Ä–æ—Å—Ç–æ –≤–∏–∫–ª–∏–∫–∞—Ç–∏
    - –ú—ñ–Ω—ñ–º—É–º –∫–æ–¥—É
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å–∞–º–∏

    ‚ùå –û–±–º–µ–∂–µ–Ω–Ω—è:
    - –ú–µ–Ω—à–µ –∫–æ–Ω—Ç—Ä–æ–ª—é –Ω–∞–¥ –ø—Ä–æ—Ü–µ—Å–æ–º
    - –ù–µ–º–æ–∂–ª–∏–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ crawler
    - –ë–∞–∑–æ–≤—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    """
    logger.info("=" * 60)
    logger.info("Level 1: Simple crawl() Function")
    logger.info("=" * 60)

    from graph_crawler import crawl

    # –ü—Ä–æ—Å—Ç–æ –≤–∏–∫–ª–∏–∫–∞—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é!
    graph = crawl(
        url="https://www.royalroad.com/",
        max_pages=15,
        max_depth=2,
        same_domain_only=True
    )

    stats = graph.get_stats()
    logger.info(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç:")
    logger.info(f"   üìÑ –°—Ç–æ—Ä—ñ–Ω–æ–∫: {stats['total_nodes']}")
    logger.info(f"   üîó –ü–æ—Å–∏–ª–∞–Ω—å: {stats['total_edges']}")
    logger.info(f"\nüí° –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–ª–∏: —à–≤–∏–¥–∫–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è, –ø—Ä–æ—Å—Ç—ñ —Å–∫—Ä–∏–ø—Ç–∏")

    return graph


def level_2_crawler_class():
    """Level 2: GraphCrawler –∫–ª–∞—Å - —Å–µ—Ä–µ–¥–Ω—ñ–π —Ä—ñ–≤–µ–Ω—å

    –ü–µ—Ä–µ–≤–∞–≥–∏:
    - –ú–æ–∂–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏
    - –ë—ñ–ª—å—à–µ –º–µ—Ç–æ–¥—ñ–≤ (save, load, export)
    - Context manager –ø—ñ–¥—Ç—Ä–∏–º–∫–∞
    - –ö—Ä–∞—â–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å

    ‚ùå –û–±–º–µ–∂–µ–Ω–Ω—è:
    - –í—Å–µ —â–µ –æ–±–º–µ–∂–µ–Ω—ñ –¥–µ—è–∫—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
    - –ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø—É –¥–æ –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
    """
    logger.info("\n" + "=" * 60)
    logger.info("Level 2: GraphCrawler Class")
    logger.info("=" * 60)

    from graph_crawler import GraphCrawler

    # –°—Ç–≤–æ—Ä—é—î–º–æ crawler –æ–±'—î–∫—Ç
    crawler = GraphCrawler(
        max_depth=2,
        max_pages=15
    )

    try:
        # –ú–æ–∂–µ–º–æ –≤–∏–∫–ª–∏–∫–∞—Ç–∏ –±–∞–≥–∞—Ç–æ —Ä–∞–∑—ñ–≤! timeout –ø–µ—Ä–µ–¥–∞—î–º–æ –≤ crawl()
        graph1 = crawler.crawl(
            url="https://www.royalroad.com/",
            timeout=60  # timeout —Ç—É—Ç, –∞ –Ω–µ –≤ __init__
        )

        # –ó–±–µ—Ä–µ–≥—Ç–∏ –≥—Ä–∞—Ñ
        # crawler.save_graph(graph1, "royalroad_graph")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats1 = graph1.get_stats()
        logger.info(f"\n–ü–µ—Ä—à–∏–π –∫—Ä–∞—É–ª—ñ–Ω–≥:")
        logger.info(f"   üìÑ –°—Ç–æ—Ä—ñ–Ω–æ–∫: {stats1['total_nodes']}")

        # –ú–æ–∂–Ω–∞ –∫—Ä–∞—É–ª–∏—Ç–∏ —ñ–Ω—à–∏–π —Å–∞–π—Ç —Ç–∏–º —Å–∞–º–∏–º crawler!
        # graph2 = crawler.crawl("https://www.royalroad.com/fictions/trending")

        logger.info(f"\nüí° –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–ª–∏: –ø–æ—Ç—Ä—ñ–±–Ω–æ –±–∞–≥–∞—Ç–æ —Ä–∞–∑—ñ–≤ –∫—Ä–∞—É–ª–∏—Ç–∏")
        logger.info(f"   –∞–±–æ –∑–±–µ—Ä—ñ–≥–∞—Ç–∏/–∑–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—Ç–∏ –≥—Ä–∞—Ñ–∏")

        return graph1

    finally:
        # –í–∞–∂–ª–∏–≤–æ –∑–∞–∫—Ä–∏—Ç–∏ —Ä–µ—Å—É—Ä—Å–∏!
        crawler.close()


def level_2_with_context_manager():
    """Level 2b: GraphCrawler –∑ context manager (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)

    –ü–µ—Ä–µ–≤–∞–≥–∏ –≤—Å—ñ —Ç—ñ —Å–∞–º—ñ + –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–∞–∫—Ä–∏—Ç—Ç—è —Ä–µ—Å—É—Ä—Å—ñ–≤
    """
    logger.info("\n" + "=" * 60)
    logger.info("Level 2b: GraphCrawler with Context Manager")
    logger.info("=" * 60)

    from graph_crawler import GraphCrawler

    # with –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞–∫—Ä–∏—î —Ä–µ—Å—É—Ä—Å–∏
    with GraphCrawler(max_depth=2, max_pages=15) as crawler:
        graph = crawler.crawl("https://www.royalroad.com/")

        stats = graph.get_stats()
        logger.info(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç:")
        logger.info(f"   üìÑ –°—Ç–æ—Ä—ñ–Ω–æ–∫: {stats['total_nodes']}")
        logger.info(f"\nüí° –ö—Ä–∞—â–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ with - –Ω–µ –∑–∞–±—É–¥–µ—Ç–µ –∑–∞–∫—Ä–∏—Ç–∏!")

        return graph


def level_3_full_container():
    """Level 3: ApplicationContainer - –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å

    –ü–µ—Ä–µ–≤–∞–≥–∏:
    - –ü–æ–≤–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –≤—Å—ñ–º–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
    - –î–æ—Å—Ç—É–ø –¥–æ event bus, storage, drivers
    - –ú–æ–∂–Ω–∞ –∑–º—ñ–Ω–∏—Ç–∏ –±—É–¥—å-—è–∫–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
    - Dependency Injection

    ‚ùå –°–∫–ª–∞–¥–Ω—ñ—à–µ:
    - –ë—ñ–ª—å—à–µ –∫–æ–¥—É
    - –ü–æ—Ç—Ä—ñ–±–Ω–æ —Ä–æ–∑—É–º—ñ—Ç–∏ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É
    """
    logger.info("\n" + "=" * 60)
    logger.info("Level 3: Full ApplicationContainer Control")
    logger.info("=" * 60)

    from graph_crawler.containers import ApplicationContainer
    from graph_crawler.core.configs import CrawlerConfig

    # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
    container = ApplicationContainer()

    try:
        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
        config = CrawlerConfig(
            url="https://www.royalroad.com/",
            max_depth=2,
            max_pages=15,
            allowed_domains = ["domain+subdomains", 'www.facebook.com']
        )
        container.config.from_pydantic(config)

        # –û—Ç—Ä–∏–º—É—î–º–æ crawler service —á–µ—Ä–µ–∑ DI
        client = container.client()

        # –ú–æ–∂–µ–º–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ –¥–æ—Å—Ç—É–ø –¥–æ event bus!
        event_bus = container.core.event_bus()

        # –ü—ñ–¥–ø–∏—Å—É—î–º–æ—Å—è –Ω–∞ –ø–æ–¥—ñ—ó
        def on_node_scanned(event_name, event_data):
            logger.info(f"   üîç Scanned: {event_data.get('url', 'unknown')}")

        event_bus.subscribe('NODE_SCANNED', on_node_scanned)

        # –ö—Ä–∞—É–ª—ñ–Ω–≥
        logger.info("\nüöÄ Starting crawl with event tracking:")
        graph = client.crawl("https://www.royalroad.com/")

        stats = graph.get_stats()
        logger.info(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç:")
        logger.info(f"   üìÑ –°—Ç–æ—Ä—ñ–Ω–æ–∫: {stats['total_nodes']}")
        logger.info(f"\nüí° –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–ª–∏: –ø–æ—Ç—Ä—ñ–±–µ–Ω –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å,")
        logger.info(f"   custom –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏, –∞–±–æ —Å–∫–ª–∞–¥–Ω–∞ –ª–æ–≥—ñ–∫–∞")

        return graph

    finally:
        # –ó–∞–∫—Ä–∏–≤–∞—î–º–æ –≤—Å—ñ —Ä–µ—Å—É—Ä—Å–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        container.shutdown_resources()


def level_3_with_custom_config():
    """Level 3b: –ö–∞—Å—Ç–æ–º–Ω–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —á–µ—Ä–µ–∑ Container

    –ü–æ–∫–∞–∑—É—î —è–∫ –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ —Ä—ñ–∑–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
    """
    logger.info("\n" + "=" * 60)
    logger.info("Level 3b: Custom Configuration")
    logger.info("=" * 60)

    from graph_crawler.containers import ApplicationContainer
    from graph_crawler.core.models import URLRule
    from graph_crawler.core.configs import CrawlerConfig, DriverConfig

    container = ApplicationContainer()

    try:
        # –î–µ—Ç–∞–ª—å–Ω–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è
        config = CrawlerConfig(
            url="https://www.royalroad.com/",
            max_depth=3,
            max_pages=20,
            driver=DriverConfig(
                request_delay=1.0,
                request_timeout=120,
            ),
            url_rules=[
                URLRule(pattern=r".*/fiction/.*", priority=10, should_scan=True),
                URLRule(pattern=r".*/forums/.*", should_scan=False),
            ]
        )

        container.config.from_pydantic(config)

        crawler_service = container.client()
        graph = crawler_service.crawl("https://www.royalroad.com/")

        stats = graph.get_stats()
        logger.info(f"\n–ó –∫–∞—Å—Ç–æ–º–Ω–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é:")
        logger.info(f"   üìÑ –°—Ç–æ—Ä—ñ–Ω–æ–∫: {stats['total_nodes']}")
        logger.info(f"   ‚è±Ô∏è Request delay: 1.0s")
        logger.info(f"   üéØ –ó URL filtering")

        return graph

    finally:
        container.shutdown_resources()


def comparison_table():
    """–ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –≤—Å—ñ—Ö —Ä—ñ–≤–Ω—ñ–≤ API"""
    logger.info("\n" + "=" * 80)
    logger.info("üìä API LEVELS COMPARISON")
    logger.info("=" * 80)

    comparison = """
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Feature     ‚îÇ Level 1: crawl() ‚îÇ Level 2: Class   ‚îÇ Level 3: Container‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ –ü—Ä–æ—Å—Ç–æ—Ç–∞    ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê          ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê            ‚îÇ ‚≠ê‚≠ê               ‚îÇ
‚îÇ –ì–Ω—É—á–∫—ñ—Å—Ç—å   ‚îÇ ‚≠ê‚≠ê              ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê            ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê          ‚îÇ
‚îÇ –ö–æ–Ω—Ç—Ä–æ–ª—å    ‚îÇ ‚≠ê‚≠ê              ‚îÇ ‚≠ê‚≠ê‚≠ê             ‚îÇ ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê          ‚îÇ
‚îÇ –ö–æ–¥ (—Ä—è–¥–∫—ñ–≤)‚îÇ 3-5 —Ä—è–¥–∫—ñ–≤       ‚îÇ 10-15 —Ä—è–¥–∫—ñ–≤     ‚îÇ 20-30 —Ä—è–¥–∫—ñ–≤     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ –ö–æ–ª–∏        ‚îÇ –®–≤–∏–¥–∫—ñ —Å–∫—Ä–∏–ø—Ç–∏   ‚îÇ –°–µ—Ä–µ–¥–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏  ‚îÇ Production       ‚îÇ
‚îÇ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ ‚îÇ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è       ‚îÇ –ë–∞–≥–∞—Ç–æ –∫—Ä–∞—É–ª—ñ–≤   ‚îÇ –°–∫–ª–∞–¥–Ω–∞ –ª–æ–≥—ñ–∫–∞   ‚îÇ
‚îÇ             ‚îÇ –ü—Ä–æ—Ç–æ—Ç–∏–ø–∏        ‚îÇ Save/Load –≥—Ä–∞—Ñ—ñ–≤ ‚îÇ Custom –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
"""

    logger.info(comparison)

    logger.info("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:")
    logger.info("   üü¢ –ù–æ–≤–∞—á–æ–∫? –ü–æ—á–∏–Ω–∞–π—Ç–µ –∑ Level 1 (crawl)")
    logger.info("   üü° –Ñ –¥–æ—Å–≤—ñ–¥? –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ Level 2 (GraphCrawler)")
    logger.info("   üî¥ Production? –ü–µ—Ä–µ—Ö–æ–¥—å—Ç–µ –Ω–∞ Level 3 (Container)")


def best_practices():
    """Best practices –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—ñ–≤–Ω—è"""
    logger.info("\n" + "=" * 80)
    logger.info("BEST PRACTICES")
    logger.info("=" * 80)

    practices = """
    
üìå Level 1 (crawl function):
   DO:
      - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –¥–ª—è —à–≤–∏–¥–∫–∏—Ö —Ç–µ—Å—Ç—ñ–≤
      - –ó–∞–≤–∂–¥–∏ –≤—Å—Ç–∞–Ω–æ–≤–ª—é–π—Ç–µ max_pages
      - –î–æ–¥–∞–≤–∞–π—Ç–µ timeout
   
   ‚ùå DON'T:
      - –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –≤ —Ü–∏–∫–ª–∞—Ö (—Å—Ç–≤–æ—Ä—é—î –Ω–æ–≤—ñ —Ä–µ—Å—É—Ä—Å–∏)
      - –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –¥–ª—è –≤–µ–ª–∏–∫–∏—Ö –ø—Ä–æ–µ–∫—Ç—ñ–≤

üìå Level 2 (GraphCrawler class):
   DO:
      - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ with statement (context manager)
      - –ü–µ—Ä–µ—ñ—Å–ø–æ–ª—å–∑—É–π—Ç–µ crawler –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Å–∞–π—Ç—ñ–≤
      - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ save/load –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
   
   ‚ùå DON'T:
      - –ù–µ –∑–∞–±—É–≤–∞–π—Ç–µ –≤–∏–∫–ª–∏–∫–∞—Ç–∏ close() –±–µ–∑ with
      - –ù–µ —Å—Ç–≤–æ—Ä—é–π—Ç–µ –±–∞–≥–∞—Ç–æ –µ–∫–∑–µ–º–ø–ª—è—Ä—ñ–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ

üìå Level 3 (ApplicationContainer):
   DO:
      - –ü—ñ–¥–ø–∏—Å—É–π—Ç–µ—Å—å –Ω–∞ –ø–æ–¥—ñ—ó –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É
      - –ù–∞–ª–∞—à—Ç–æ–≤—É–π—Ç–µ –≤—Å—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ —á–µ—Ä–µ–∑ config
      - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –¥–ª—è —Å–∫–ª–∞–¥–Ω–æ—ó –±—ñ–∑–Ω–µ—Å-–ª–æ–≥—ñ–∫–∏
   
   ‚ùå DON'T:
      - –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ —è–∫—â–æ –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω –ø–æ–≤–Ω–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å
      - –ó–∞–≤–∂–¥–∏ –≤–∏–∫–ª–∏–∫–∞–π—Ç–µ shutdown_resources()
"""

    logger.info(practices)


if __name__ == "__main__":
    print("\nüöÄ Starting API Levels Examples\n")

    try:
        # –ü–æ–∫–∞–∑—É—î–º–æ –≤—Å—ñ —Ç—Ä–∏ —Ä—ñ–≤–Ω—ñ
        # graph1 = level_1_simple_crawl()
        # graph2 = level_2_crawler_class()
        # graph3 = level_2_with_context_manager()
        # graph4 = level_3_full_container()
        graph5 = level_3_with_custom_config()

        # –ü–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–∞ —Ç–∞–±–ª–∏—Ü—è
        comparison_table()

        # Best practices
        best_practices()

        print("\n" + "=" * 80)
        print("All API levels demonstrated successfully!")
        print("=" * 80)

    except Exception as e:
        logger.error(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        raise
