# Distributed Crawling Configuration
# Використання: crawler = EasyDistributedCrawler.from_yaml("config.yaml")

broker:
  type: redis
  host: server11.example.com
  port: 6379
  db: 0
  password: null  # або "your_password"

database:
  type: mongodb
  host: server12.example.com
  port: 27017
  database: crawler_results
  username: null
  password: null

proxy:
  enabled: false
  type: file
  source: ./proxies.txt

crawl_task:
  urls:
    - https://example1.com
    - https://example2.com
  max_depth: 3
  max_pages: 1000
  extractors:
    - phones
    - emails
    - prices
  custom_plugins: []
    # - "myapp.plugins.CustomExtractorPlugin"

# Celery workers settings
workers: 10
task_time_limit: 600
worker_prefetch_multiplier: 4
