"""
============================================================
–¢–†–ê–°–£–í–ê–ù–ù–Ø 12: –ü–û–í–ù–ò–ô –í–ò–ö–õ–ò–ö –ó –ö–ê–°–¢–û–ú–ù–û–Æ –ù–û–î–û–Æ
============================================================

–¶–µ–π —Ñ–∞–π–ª –ø–æ–∫–∞–∑—É—î —è–∫ –ø—Ä–∞—Ü—é—é—Ç—å –∫–∞—Å—Ç–æ–º–Ω—ñ Node –∫–ª–∞—Å–∏:
- –Ø–∫ —É—Å–ø–∞–¥–∫—É–≤–∞—Ç–∏ Node
- –Ø–∫ –¥–æ–¥–∞—Ç–∏ –∫–∞—Å—Ç–æ–º–Ω—ñ –ø–æ–ª—è
- –Ø–∫ –ø–µ—Ä–µ–≤–∏–∑–Ω–∞—á–∏—Ç–∏ _update_from_context
- –Ø–∫ —Ü–µ –≤–ø–ª–∏–≤–∞—î –Ω–∞ –ø—Ä–æ—Ü–µ—Å

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
    python 12_full_trace_custom_node.py
"""

import sys
import os
import asyncio
import logging
from datetime import datetime
from typing import Optional, List
from pydantic import Field

# –®–ª—è—Ö –¥–æ –ø—Ä–æ–µ–∫—Ç—É
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, PROJECT_ROOT)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-7s | %(message)s',
    datefmt='%H:%M:%S'
)

logger = logging.getLogger(__name__)


def print_header(title: str):
    print("\n" + "=" * 100)
    print(f"  {title}")
    print("=" * 100)


def print_section(title: str):
    print(f"\n{'‚îÄ' * 80}")
    print(f"  üìå {title}")
    print(f"{'‚îÄ' * 80}")


async def trace_custom_node():
    """
    –¢—Ä–∞—Å—É–≤–∞–Ω–Ω—è –∑ –∫–∞—Å—Ç–æ–º–Ω–æ—é –Ω–æ–¥–æ—é.
    """
    print_header("–¢–†–ê–°–£–í–ê–ù–ù–Ø: –í–ò–ö–õ–ò–ö –ó –ö–ê–°–¢–û–ú–ù–û–Æ –ù–û–î–û–Æ")
    
    import graph_crawler as gc
    from graph_crawler import AsyncDriver
    from graph_crawler.core.models import EdgeCreationStrategy
    
    # ============================================================
    print_section("–ï–¢–ê–ü 1: –ë–ê–ó–û–í–ò–ô –ö–õ–ê–° NODE")
    # ============================================================
    
    print("""
    –ë–∞–∑–æ–≤–∏–π Node (graph_crawler/core/node.py) - Pydantic –º–æ–¥–µ–ª—å:
    
    class Node(BaseModel):
        # –ë–∞–∑–æ–≤—ñ –ø–æ–ª—è (–∑–∞–≤–∂–¥–∏ —î)
        url: str
        node_id: str = Field(default_factory=uuid4)
        depth: int = 0
        should_scan: bool = True
        can_create_edges: bool = True
        created_at: datetime = Field(default_factory=now)
        
        # –ü—ñ—Å–ª—è —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è
        metadata: Dict = Field(default_factory=dict)
        user_data: Dict = Field(default_factory=dict)
        scanned: bool = False
        response_status: Optional[int] = None
        content_hash: Optional[str] = None
        
        # v3.0: –î–∏–Ω–∞–º—ñ—á–Ω–∏–π –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç
        priority: Optional[int] = Field(default=None, ge=1, le=10)
        
        # –ñ–∏—Ç—Ç—î–≤–∏–π —Ü–∏–∫–ª
        lifecycle_stage: NodeLifecycle = NodeLifecycle.URL_STAGE
    """)
    
    # ============================================================
    print_section("–ï–¢–ê–ü 2: –°–¢–í–û–†–ï–ù–ù–Ø –ö–ê–°–¢–û–ú–ù–û–á –ù–û–î–ò")
    # ============================================================
    
    class TextNode(gc.Node):
        """
        –ö–∞—Å—Ç–æ–º–Ω–∞ –Ω–æ–¥–∞ —â–æ –≤–∏—Ç—è–≥—É—î —Ç–µ–∫—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏.
        
        –£—Å–ø–∞–¥–∫–æ–≤—É—î –≤—Å—ñ –ø–æ–ª—è Node —Ç–∞ –¥–æ–¥–∞—î:
        - text: –æ—á–∏—â–µ–Ω–∏–π —Ç–µ–∫—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        - word_count: –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ª—ñ–≤
        """
        
        # –ö–∞—Å—Ç–æ–º–Ω—ñ –ø–æ–ª—è (Pydantic Fields)
        text: Optional[str] = Field(default=None, description="–¢–µ–∫—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏")
        word_count: int = Field(default=0, description="–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ª—ñ–≤")
        
        def _update_from_context(self, context):
            """
            –¶–µ–π –º–µ—Ç–æ–¥ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ü–Ü–°–õ–Ø ON_HTML_PARSED –ø–ª–∞–≥—ñ–Ω—ñ–≤,
            –ü–ï–†–ï–î ON_AFTER_SCAN –ø–ª–∞–≥—ñ–Ω–∞–º–∏.
            
            –¢—É—Ç –º–æ–∂–Ω–∞ –≤–∏—Ç—è–≥–Ω—É—Ç–∏ –¥–∞–Ω—ñ –∑ html_tree.
            """
            # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–ª–∏–∫–∞—î–º–æ –±–∞—Ç—å–∫—ñ–≤—Å—å–∫–∏–π –º–µ—Ç–æ–¥
            super()._update_from_context(context)
            
            print(f"\n  üîß TextNode._update_from_context()")
            print(f"     ‚îú‚îÄ‚îÄ URL: {self.url}")
            print(f"     ‚îú‚îÄ‚îÄ html_tree –ø—Ä–∏—Å—É—Ç–Ω—ñ–π: {context.html_tree is not None}")
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç —è–∫—â–æ —î html_tree
            if context.html_tree:
                # BeautifulSoup API
                raw_text = context.html_tree.get_text(separator=' ', strip=True)
                # –û—á–∏—â–µ–Ω–Ω—è
                self.text = ' '.join(raw_text.split())
                self.word_count = len(self.text.split())
                
                print(f"     ‚îú‚îÄ‚îÄ –¢–µ–∫—Å—Ç –≤–∏—Ç—è–≥–Ω—É—Ç–æ: {len(self.text)} —Å–∏–º–≤–æ–ª—ñ–≤")
                print(f"     ‚îî‚îÄ‚îÄ –°–ª—ñ–≤: {self.word_count}")
    
    print("""
    TextNode —É—Å–ø–∞–¥–∫–æ–≤—É—î gc.Node —Ç–∞ –¥–æ–¥–∞—î:
    
    class TextNode(gc.Node):
        text: Optional[str] = None       # –¢–µ–∫—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        word_count: int = 0              # –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ª—ñ–≤
        
        def _update_from_context(self, context):
            # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç –∑ html_tree
            ...
    
    –ö–æ–ª–∏ –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è _update_from_context:
    
    node.process_html(html)
    ‚îú‚îÄ‚îÄ parse(html) ‚Üí html_tree
    ‚îú‚îÄ‚îÄ ON_BEFORE_SCAN –ø–ª–∞–≥—ñ–Ω–∏
    ‚îú‚îÄ‚îÄ ON_HTML_PARSED –ø–ª–∞–≥—ñ–Ω–∏
    ‚îú‚îÄ‚îÄ _update_from_context(context)  ‚Üê –¢–£–¢!
    ‚îî‚îÄ‚îÄ ON_AFTER_SCAN –ø–ª–∞–≥—ñ–Ω–∏
    """)
    
    # ============================================================
    print_section("–ï–¢–ê–ü 3: –ó–ê–ü–£–°–ö –ö–†–ê–£–õ–Ü–ù–ì–£")
    # ============================================================
    
    print("\n  üöÄ –ó–∞–ø—É—Å–∫ –∫—Ä–∞—É–ª—ñ–Ω–≥—É –∑ TextNode...\n")
    
    start_time = datetime.now()
    
    graph = await gc.crawl(
        "https://httpbin.org/html",
        max_depth=1,
        max_pages=2,
        driver=AsyncDriver,
        node_class=TextNode,  # ‚Üê –ö–∞—Å—Ç–æ–º–Ω–∞ –Ω–æ–¥–∞!
        edge_strategy=EdgeCreationStrategy.NEW_ONLY,
    )
    
    duration = (datetime.now() - start_time).total_seconds()
    
    # ============================================================
    print_section("–ï–¢–ê–ü 4: –í–ù–£–¢–†–Ü–®–ù–Ü–ô –ü–†–û–¶–ï–° –°–¢–í–û–†–ï–ù–ù–Ø –ù–û–î–ò")
    # ============================================================
    
    print("""
    –ö–æ–ª–∏ –≤–∫–∞–∑–∞–Ω–æ node_class=TextNode:
    
    1. GraphSpider –æ—Ç—Ä–∏–º—É—î node_class –∑ config:
       self.config.custom_node_class = TextNode
    
    2. –ü—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ root_node:
       node_class = self.config.custom_node_class or Node
       root_node = node_class(url=url, depth=0)
       
    3. –ü—Ä–∏ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—ñ child nodes –≤ LinkProcessor:
       node_class = self.custom_node_class or Node
       child_node = node_class(url=url, depth=parent_depth+1)
    
    4. Pydantic –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ:
       - –í–∞–ª—ñ–¥—É—î –≤—Å—ñ –ø–æ–ª—è (–±–∞–∑–æ–≤—ñ + –∫–∞—Å—Ç–æ–º–Ω—ñ)
       - –í—Å—Ç–∞–Ω–æ–≤–ª—é—î defaults
       - –í–∏–∫–ª–∏–∫–∞—î model_post_init()
    
    5. –ü—Ä–∏ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—ñ:
       node.process_html(html)
       ‚îî‚îÄ‚îÄ _update_from_context()  ‚Üê –ö–∞—Å—Ç–æ–º–Ω–∞ –ª–æ–≥—ñ–∫–∞ —Ç—É—Ç!
    """)
    
    # ============================================================
    print_section("–ï–¢–ê–ü 5: –†–ï–ó–£–õ–¨–¢–ê–¢–ò")
    # ============================================================
    
    print(f"\n  ‚è±Ô∏è –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {duration:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"  üìä –ó–Ω–∞–π–¥–µ–Ω–æ –Ω–æ–¥: {len(graph.nodes)}")
    
    print("\n  üìã –ö–∞—Å—Ç–æ–º–Ω—ñ –ø–æ–ª—è TextNode:")
    for node_id, node in graph.nodes.items():
        print(f"\n      Node: {node.url}")
        print(f"      ‚îú‚îÄ‚îÄ –¢–∏–ø: {type(node).__name__}")
        print(f"      ‚îú‚îÄ‚îÄ scanned: {node.scanned}")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–∞—Å—Ç–æ–º–Ω—ñ –ø–æ–ª—è
        if isinstance(node, TextNode):
            print(f"      ‚îú‚îÄ‚îÄ word_count: {node.word_count}")
            if node.text:
                preview = node.text[:100] + '...' if len(node.text) > 100 else node.text
                print(f"      ‚îî‚îÄ‚îÄ text preview: '{preview}'")
        else:
            print(f"      ‚îî‚îÄ‚îÄ ‚ö†Ô∏è –ù–µ TextNode!")
    
    print_header("–¢–†–ê–°–£–í–ê–ù–ù–Ø –ó–ê–í–ï–†–®–ï–ù–û")
    return graph


if __name__ == "__main__":
    print("\n" + "*" * 100)
    print("  GRAPHCRAWLER v3.0 - –¢–†–ê–°–£–í–ê–ù–ù–Ø –ó –ö–ê–°–¢–û–ú–ù–û–Æ –ù–û–î–û–Æ")
    print("*" * 100)
    
    graph = asyncio.run(trace_custom_node())
    print("\n‚úÖ –¢—Ä–∞—Å—É–≤–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
