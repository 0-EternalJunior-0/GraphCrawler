"""
============================================================
Ğ¢Ğ•Ğ¡Ğ¢ 6: ĞŸĞĞ’ĞĞ˜Ğ™ ĞŸĞ Ğ˜ĞšĞ›ĞĞ” - playtechpeople.com
============================================================

ĞŸĞ¾Ğ²Ğ½Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ñ–Ñ Ğ²ÑÑ–Ñ… Ğ¼Ğ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚ĞµĞ¹ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ ÑĞ°Ğ¹Ñ‚Ñ–:
- ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ğ° Node
- URL Rules
- ĞŸĞ»Ğ°Ğ³Ñ–Ğ½Ğ¸
- Edge Strategy
- Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ²Ğ¸Ğ²Ñ–Ğ´ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ–Ğ²
"""

import sys
import os
import asyncio
import logging
from datetime import datetime
from typing import Optional, Any
from pydantic import Field

# Ğ¨Ğ»ÑÑ… Ğ´Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, PROJECT_ROOT)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-7s | %(message)s',
    datefmt='%H:%M:%S'
)

logger = logging.getLogger(__name__)


def print_section(title: str):
    print("\n" + "=" * 80)
    print(f" {title}")
    print("=" * 80)


def print_step(step: int, description: str):
    print(f"\n{'â”€' * 60}")
    print(f"  ĞšĞ ĞĞš {step}: {description}")
    print(f"{'â”€' * 60}")


async def test_full_example():
    """
    ĞŸĞ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸ĞºĞ»Ğ°Ğ´ Ğ½Ğ° Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼Ñƒ ÑĞ°Ğ¹Ñ‚Ñ–.
    """
    import graph_crawler as gc
    from graph_crawler import URLRule, AsyncDriver
    from graph_crawler.plugins.node import BaseNodePlugin, NodePluginType
    from graph_crawler.core.models import EdgeCreationStrategy
    
    print_section("Ğ¢Ğ•Ğ¡Ğ¢ 6: ĞŸĞĞ’ĞĞ˜Ğ™ ĞŸĞ Ğ˜ĞšĞ›ĞĞ” - playtechpeople.com")
    
    # ============================================================
    print_step(1, "Ğ’Ğ˜Ğ—ĞĞĞ§Ğ•ĞĞĞ¯ ĞšĞĞ¡Ğ¢ĞĞœĞĞĞ‡ ĞĞĞ”Ğ˜")
    # ============================================================
    
    class CastomNode(gc.Node):
        """
        ĞšĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ğ° Node Ğ´Ğ»Ñ Ğ·Ğ±Ğ¾Ñ€Ñƒ Ñ‚ĞµĞºÑÑ‚Ñƒ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ¸.
        """
        text: Optional[str] = Field(default=None, description="Ğ¢ĞµĞºÑÑ‚ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ¸")
        word_count: int = Field(default=0, description="ĞšÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ ÑĞ»Ñ–Ğ²")
        
        def _update_from_context(self, context: Any):
            super()._update_from_context(context)
            if context.html_tree:
                raw_text = context.html_tree.text
                clean_text = ' '.join(raw_text.split())
                clean_text = clean_text.replace('\n', ' ').replace('\t', ' ')
                self.text = clean_text[:1000]  # ĞĞ±Ğ¼ĞµĞ¶ÑƒÑ”Ğ¼Ğ¾
                self.word_count = len(clean_text.split())
    
    print("  CastomNode Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¾:")
    print("  - text: Ñ‚ĞµĞºÑÑ‚ ÑÑ‚Ğ¾Ñ€Ñ–Ğ½ĞºĞ¸")
    print("  - word_count: ĞºÑ–Ğ»ÑŒĞºÑ–ÑÑ‚ÑŒ ÑĞ»Ñ–Ğ²")
    
    # ============================================================
    print_step(2, "Ğ’Ğ˜Ğ—ĞĞĞ§Ğ•ĞĞĞ¯ URL RULES")
    # ============================================================
    
    url_rules = [
        # Ğ‘Ğ»Ğ¾Ğ³ - ÑĞºĞ°Ğ½ÑƒÑ”Ğ¼Ğ¾ Ğ°Ğ»Ğµ Ğ½Ğµ Ğ¹Ğ´ĞµĞ¼Ğ¾ Ğ¿Ğ¾ Ğ²Ğ½ÑƒÑ‚Ñ€Ñ–ÑˆĞ½Ñ–Ñ… Ğ¿Ğ¾ÑĞ¸Ğ»Ğ°Ğ½Ğ½ÑÑ…
        URLRule(
            pattern="/blog/",
            should_follow_links=False,
            should_scan=True,
            priority=5
        ),
        # Ğ’Ğ°ĞºĞ°Ğ½ÑÑ–Ñ— - Ğ²Ğ¸ÑĞ¾ĞºĞ¸Ğ¹ Ğ¿Ñ€Ñ–Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚
        URLRule(
            pattern="jobs.smartrecruiters.com",
            should_follow_links=False,
            should_scan=True,
            priority=6
        ),
    ]
    
    print("  URL Rules:")
    for rule in url_rules:
        print(f"  - pattern='{rule.pattern}' priority={rule.priority}")
    
    # ============================================================
    print_step(3, "Ğ’Ğ˜Ğ—ĞĞĞ§Ğ•ĞĞĞ¯ ĞŸĞ›ĞĞ“Ğ†ĞĞ")
    # ============================================================
    
    class AnalyticsPlugin(BaseNodePlugin):
        """ĞŸĞ»Ğ°Ğ³Ñ–Ğ½ Ğ´Ğ»Ñ Ğ·Ğ±Ğ¾Ñ€Ñƒ Ğ°Ğ½Ğ°Ğ»Ñ–Ñ‚Ğ¸ĞºĞ¸."""
        
        def __init__(self, config=None):
            super().__init__(config or {})
            self.pages_analyzed = 0
        
        @property
        def name(self) -> str:
            return "AnalyticsPlugin"
        
        @property
        def plugin_type(self) -> NodePluginType:
            return NodePluginType.ON_AFTER_SCAN
        
        def execute(self, context):
            self.pages_analyzed += 1
            context.user_data['analyzed_at'] = datetime.now().isoformat()
            context.user_data['analysis_id'] = self.pages_analyzed
            return context
    
    analytics_plugin = AnalyticsPlugin()
    print("  AnalyticsPlugin Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¾")
    
    # ============================================================
    print_step(4, "Ğ—ĞĞŸĞ£Ğ¡Ğš ĞšĞ ĞĞ£Ğ›Ğ†ĞĞ“Ğ£")
    # ============================================================
    
    print("""
    >>> graph = gc.crawl(
    ...     "https://www.playtechpeople.com/",
    ...     max_depth=3,
    ...     max_pages=2,
    ...     node_class=CastomNode,
    ...     driver=AsyncDriver,
    ...     url_rules=url_rules,
    ...     edge_strategy=EdgeCreationStrategy.NEW_ONLY,
    ...     plugins=[analytics_plugin]
    ... )
    """)
    
    start_time = datetime.now()
    
    graph = await gc.crawl(
        "https://www.playtechpeople.com/",
        max_depth=3,
        max_pages=2,
        node_class=CastomNode,
        driver=AsyncDriver,
        url_rules=url_rules,
        edge_strategy=EdgeCreationStrategy.NEW_ONLY,
        plugins=[analytics_plugin]
    )
    
    duration = (datetime.now() - start_time).total_seconds()
    
    # ============================================================
    print_step(5, "Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ˜")
    # ============================================================
    
    print(f"\n  â±  Ğ§Ğ°Ñ Ğ²Ğ¸ĞºĞ¾Ğ½Ğ°Ğ½Ğ½Ñ: {duration:.2f} ÑĞµĞºÑƒĞ½Ğ´")
    print(f"  ğŸ“Š Ğ¡Ñ‚Ğ¾Ñ€Ñ–Ğ½Ğ¾Ğº Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¾: {analytics_plugin.pages_analyzed}")
    print(f"  ğŸ”— Ğ’ÑÑŒĞ¾Ğ³Ğ¾ Ğ½Ğ¾Ğ´: {len(graph.nodes)}")
    print(f"  ğŸ”— Ğ’ÑÑŒĞ¾Ğ³Ğ¾ edges: {len(graph.edges)}")
    
    stats = graph.get_stats()
    print(f"\n  Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ³Ñ€Ğ°Ñ„Ğ°:")
    print(f"    - nodes_count: {stats['nodes_count']}")
    print(f"    - edges_count: {stats['edges_count']}")
    print(f"    - max_depth: {stats['max_depth']}")
    
    print("\n  Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ° Ñ–Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ñ–Ñ Ğ¿Ğ¾ Ğ½Ğ¾Ğ´Ğ°Ñ…:")
    print("  " + "-" * 70)
    
    for node_id, node in graph.nodes.items():
        print(f"\n  ğŸ“„ {node.url}")
        print(f"     depth: {node.depth}")
        print(f"     scanned: {node.scanned}")
        print(f"     title: {node.title[:50] + '...' if node.title and len(node.title) > 50 else node.title}")
        
        if isinstance(node, CastomNode):
            print(f"     word_count: {node.word_count}")
            if node.text:
                preview = node.text[:100] + "..." if len(node.text) > 100 else node.text
                print(f"     text: '{preview}'")
        
        if node.user_data:
            print(f"     user_data keys: {list(node.user_data.keys())}")
    
    # ============================================================
    print_step(6, "ĞŸĞĞ’ĞĞ˜Ğ™ Ğ›ĞĞĞ¦Ğ®Ğ–ĞĞš Ğ’Ğ˜ĞšĞ›Ğ˜ĞšĞ†Ğ’")
    # ============================================================
    
    print("""
    ĞŸĞĞ’ĞĞ˜Ğ™ Ğ›ĞĞĞ¦Ğ®Ğ–ĞĞš:
    
    gc.crawl("https://www.playtechpeople.com/", ...)
    â”‚
    â”œâ”€â”€ api/simple.py::crawl()
    â”‚   â”œâ”€â”€ ApplicationContainer()          # DI ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
    â”‚   â”œâ”€â”€ CrawlerConfig(
    â”‚   â”‚       url=url,
    â”‚   â”‚       max_depth=3,
    â”‚   â”‚       max_pages=2,
    â”‚   â”‚       custom_node_class=CastomNode,
    â”‚   â”‚       url_rules=url_rules,
    â”‚   â”‚       node_plugins=[analytics_plugin],
    â”‚   â”‚       edge_strategy=NEW_ONLY
    â”‚   â”‚   )
    â”‚   â”œâ”€â”€ create_driver(AsyncDriver)      # DriverFactory
    â”‚   â””â”€â”€ GraphCrawlerClient.crawl()
    â”‚       â”‚
    â”‚       â”œâ”€â”€ GraphSpider(config)
    â”‚       â”‚   â”œâ”€â”€ Graph()                 # Ğ“Ñ€Ğ°Ñ„ Ğ´Ğ»Ñ Ğ·Ğ±ĞµÑ€Ñ–Ğ³Ğ°Ğ½Ğ½Ñ
    â”‚       â”‚   â”œâ”€â”€ CrawlScheduler(url_rules)  # Ğ§ĞµÑ€Ğ³Ğ° Ğ· Ğ¿Ñ€Ñ–Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ°Ğ¼Ğ¸
    â”‚       â”‚   â”œâ”€â”€ NodeScanner(driver, plugins)
    â”‚       â”‚   â””â”€â”€ LinkProcessor(custom_node_class, url_rules, edge_strategy)
    â”‚       â”‚
    â”‚       â””â”€â”€ spider.crawl()
    â”‚           â””â”€â”€ CrawlCoordinator.coordinate()
    â”‚               â””â”€â”€ _crawl_sequential_mode()
    â”‚                   â”‚
    â”‚                   â”œâ”€â”€ LOOP:
    â”‚                   â”‚   â”œâ”€â”€ scheduler.get_next()     # Ğ‘ĞµÑ€Ğµ node Ğ·Ğ° priority
    â”‚                   â”‚   â”‚
    â”‚                   â”‚   â”œâ”€â”€ scanner.scan_node(node)
    â”‚                   â”‚   â”‚   â”œâ”€â”€ driver.fetch(url)   # HTTP Ğ·Ğ°Ğ¿Ğ¸Ñ‚
    â”‚                   â”‚   â”‚   â”œâ”€â”€ parser.parse(html)  # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ HTML
    â”‚                   â”‚   â”‚   â”œâ”€â”€ plugins[ON_AFTER_SCAN].execute()
    â”‚                   â”‚   â”‚   â”œâ”€â”€ plugins[ON_AFTER_PARSE].execute()  # AnalyticsPlugin
    â”‚                   â”‚   â”‚   â””â”€â”€ node._update_from_context()  # CastomNode
    â”‚                   â”‚   â”‚
    â”‚                   â”‚   â”œâ”€â”€ [post_scan_hooks]       # v3.0 hooks
    â”‚                   â”‚   â”‚
    â”‚                   â”‚   â””â”€â”€ processor.process_links()
    â”‚                   â”‚       â”œâ”€â”€ _should_scan_url()  # URLRule + filters
    â”‚                   â”‚       â”œâ”€â”€ CastomNode(url=link)  # Ğ¡Ñ‚Ğ²Ğ¾Ñ€ĞµĞ½Ğ½Ñ child
    â”‚                   â”‚       â”œâ”€â”€ _should_create_edge()  # EdgeStrategy
    â”‚                   â”‚       â””â”€â”€ scheduler.add_node()   # Ğ”Ğ¾ Ñ‡ĞµÑ€Ğ³Ğ¸
    â”‚                   â”‚
    â”‚                   â””â”€â”€ return graph
    â”‚
    â””â”€â”€ return graph
    """)
    
    print_section("Ğ¢Ğ•Ğ¡Ğ¢ 6 Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ")
    return graph


if __name__ == "__main__":
    print("\n" + "*" * 80)
    print("  GRAPHCRAWLER v3.0 - TRACING TEST 06: FULL EXAMPLE")
    print("*" * 80)
    
    graph = asyncio.run(test_full_example())
    
    print("\nâœ… Ğ¢ĞµÑÑ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾ ÑƒÑĞ¿Ñ–ÑˆĞ½Ğ¾!")
