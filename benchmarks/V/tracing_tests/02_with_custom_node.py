"""
============================================================
–¢–ï–°–¢ 2: –ö–†–ê–£–õ–Ü–ù–ì –ó –ö–ê–°–¢–û–ú–ù–û–Æ –ù–û–î–û–Æ
============================================================

–ü–æ–∫–∞–∑—É—î:
1. –Ø–∫ —Å—Ç–≤–æ—Ä–∏—Ç–∏ –≤–ª–∞—Å–Ω–∏–π –∫–ª–∞—Å Node
2. –Ø–∫ Node –æ—Ç—Ä–∏–º—É—î –¥–∞–Ω—ñ –∑ context
3. Lifecycle Node: URL_STAGE -> BEFORE_FETCH -> AFTER_FETCH -> AFTER_PARSE
4. –Ø–∫ user_data –∑–±–µ—Ä—ñ–≥–∞—î custom –ø–æ–ª—è
"""

import sys
import os
import asyncio
import logging
from datetime import datetime
from typing import Optional, Any
from pydantic import Field

# –®–ª—è—Ö –¥–æ –ø—Ä–æ–µ–∫—Ç—É
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, PROJECT_ROOT)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-7s | %(message)s',
    datefmt='%H:%M:%S'
)

logger = logging.getLogger(__name__)


def print_section(title: str):
    print("\n" + "=" * 80)
    print(f" {title}")
    print("=" * 80)


def print_step(step: int, description: str):
    print(f"\n{'‚îÄ' * 60}")
    print(f"  –ö–†–û–ö {step}: {description}")
    print(f"{'‚îÄ' * 60}")


async def test_custom_node():
    """
    –¢–µ—Å—Ç –∑ –∫–∞—Å—Ç–æ–º–Ω–æ—é Node.
    """
    import graph_crawler as gc
    from graph_crawler import AsyncDriver
    from graph_crawler.core.models import EdgeCreationStrategy
    
    print_section("–¢–ï–°–¢ 2: –ö–ê–°–¢–û–ú–ù–ê –ù–û–î–ê (CustomNode)")
    
    # ============================================================
    print_step(1, "–í–ò–ó–ù–ê–ß–ï–ù–ù–Ø –ö–ê–°–¢–û–ú–ù–û–ì–û –ö–õ–ê–°–£ NODE")
    # ============================================================
    
    print("""
    –ö–∞—Å—Ç–æ–º–Ω–∞ Node –¥–æ–∑–≤–æ–ª—è—î:
    - –î–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –ø–æ–ª—è (text, keywords, sentiment, etc)
    - –ü–µ—Ä–µ–≤–∏–∑–Ω–∞—á–∏—Ç–∏ _update_from_context() –¥–ª—è custom logic
    - –ó–±–µ—Ä—ñ–≥–∞—Ç–∏ ML features –ø—Ä—è–º–æ –≤ –Ω–æ–¥—ñ
    """)
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –∫–∞—Å—Ç–æ–º–Ω—É –Ω–æ–¥—É
    class CustomNode(gc.Node):
        """
        –ö–∞—Å—Ç–æ–º–Ω–∞ Node –∑ –¥–æ–¥–∞—Ç–∫–æ–≤–∏–º–∏ –ø–æ–ª—è–º–∏.
        
        –ü–æ–ª—è:
        - text: –û—á–∏—â–µ–Ω–∏–π —Ç–µ–∫—Å—Ç —Å—Ç–æ—Ä—ñ–Ω–∫–∏
        - word_count: –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ª—ñ–≤
        - has_forms: –ß–∏ —î —Ñ–æ—Ä–º–∏ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ
        """
        text: Optional[str] = Field(default=None, description="–û—á–∏—â–µ–Ω–∏–π —Ç–µ–∫—Å—Ç")
        word_count: int = Field(default=0, description="–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Å–ª—ñ–≤")
        has_forms: bool = Field(default=False, description="–ß–∏ —î —Ñ–æ—Ä–º–∏")
        
        def _update_from_context(self, context: Any):
            """
            –í–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è –ü–Ü–°–õ–Ø –ø–∞—Ä—Å–∏–Ω–≥—É HTML.
            
            context –º—ñ—Å—Ç–∏—Ç—å:
            - context.url: URL —Å—Ç–æ—Ä—ñ–Ω–∫–∏
            - context.html_tree: Parsed HTML (lxml/BeautifulSoup)
            - context.parser: –ü–∞—Ä—Å–µ—Ä –∑ –º–µ—Ç–æ–¥–∞–º–∏
            - context.response_data: Raw response
            """
            # –°–ø–æ—á–∞—Ç–∫—É –≤–∏–∫–ª–∏–∫–∞—î–º–æ –±–∞—Ç—å–∫—ñ–≤—Å—å–∫–∏–π –º–µ—Ç–æ–¥
            super()._update_from_context(context)
            
            print(f"\n  üìù CustomNode._update_from_context() called for {self.url}")
            
            if context.html_tree:
                # –í–∏—Ç—è–≥—É—î–º–æ —Ç–µ–∫—Å—Ç
                raw_text = context.html_tree.text
                clean_text = ' '.join(raw_text.split())
                self.text = clean_text[:500]  # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É
                
                # –†–∞—Ö—É—î–º–æ —Å–ª–æ–≤–∞
                self.word_count = len(clean_text.split())
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Ñ–æ—Ä–º
                # BeautifulSoup API (–∑–∞–º—ñ—Å—Ç—å xpath)
                if hasattr(context.html_tree, 'find_all'):
                    forms = context.html_tree.find_all('form')
                    self.has_forms = len(forms) > 0
                elif hasattr(context.html_tree, 'xpath'):
                    # Fallback –¥–ª—è lxml —è–∫—â–æ —Ö—Ç–æ—Å—å –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î LxmlAdapter
                    forms = context.html_tree.xpath('//form')
                    self.has_forms = len(forms) > 0
                
                print(f"    ‚úì text length: {len(self.text or '')} chars")
                print(f"    ‚úì word_count: {self.word_count}")
                print(f"    ‚úì has_forms: {self.has_forms}")
    
    print("\n  CustomNode –∫–ª–∞—Å –≤–∏–∑–Ω–∞—á–µ–Ω–æ:")
    print(f"  >>> class CustomNode(gc.Node):")
    print(f"  >>>     text: Optional[str]")
    print(f"  >>>     word_count: int")
    print(f"  >>>     has_forms: bool")
    print(f"  >>>     def _update_from_context(self, context): ...")
    
    # ============================================================
    print_step(2, "LIFECYCLE –ù–û–î–ò")
    # ============================================================
    
    print("""
    Node –ø—Ä–æ—Ö–æ–¥–∏—Ç—å —á–µ—Ä–µ–∑ —Å—Ç–∞–¥—ñ—ó (NodeLifecycle):
    
    1. URL_STAGE       - Node —Å—Ç–≤–æ—Ä–µ–Ω–∞ –∑ URL (—â–µ –Ω–µ fetched)
    2. BEFORE_FETCH    - –ü–µ—Ä–µ–¥ HTTP –∑–∞–ø–∏—Ç–æ–º
    3. AFTER_FETCH     - –ü—ñ—Å–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è response
    4. AFTER_PARSE     - –ü—ñ—Å–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É HTML ‚Üê _update_from_context()
    
    –ü–ª–∞–≥—ñ–Ω–∏ –º–æ–∂—É—Ç—å –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏—Å—å –Ω–∞ –∫–æ–∂–Ω—ñ–π —Å—Ç–∞–¥—ñ—ó!
    """)
    
    # ============================================================
    print_step(3, "–ó–ê–ü–£–°–ö –ö–†–ê–£–õ–Ü–ù–ì–£ –ó –ö–ê–°–¢–û–ú–ù–û–Æ –ù–û–î–û–Æ")
    # ============================================================
    
    print("\n  >>> graph = await gc.crawl(")
    print("  ...     'https://httpbin.org/forms/post',")
    print("  ...     max_depth=1,")
    print("  ...     max_pages=2,")
    print("  ...     node_class=CustomNode,  # <-- –ö–∞—Å—Ç–æ–º–Ω–∞ Node!")
    print("  ...     driver=AsyncDriver,")
    print("  ... )")
    
    start_time = datetime.now()
    
    graph = await gc.crawl(
        "https://httpbin.org/forms/post",
        max_depth=1,
        max_pages=2,
        node_class=CustomNode,
        driver=AsyncDriver,
        edge_strategy=EdgeCreationStrategy.NEW_ONLY,
    )
    
    duration = (datetime.now() - start_time).total_seconds()
    
    # ============================================================
    print_step(4, "–†–ï–ó–£–õ–¨–¢–ê–¢–ò")
    # ============================================================
    
    print(f"\n  –ö—Ä–∞—É–ª—ñ–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {duration:.2f} —Å–µ–∫—É–Ω–¥!")
    print(f"  –ó–Ω–∞–π–¥–µ–Ω–æ –Ω–æ–¥: {len(graph.nodes)}")
    
    print("\n  –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø–æ –Ω–æ–¥–∞—Ö:")
    for node_id, node in graph.nodes.items():
        print(f"\n  Node: {node.url}")
        print(f"    - type: {type(node).__name__}")
        print(f"    - depth: {node.depth}")
        print(f"    - scanned: {node.scanned}")
        
        # –ö–∞—Å—Ç–æ–º–Ω—ñ –ø–æ–ª—è
        if isinstance(node, CustomNode):
            print(f"    - word_count: {node.word_count}")
            print(f"    - has_forms: {node.has_forms}")
            if node.text:
                preview = node.text[:100] + "..." if len(node.text) > 100 else node.text
                print(f"    - text preview: '{preview}'")
    
    # ============================================================
    print_step(5, "–í–ù–£–¢–†–Ü–®–ù–Ø –°–¢–†–£–ö–¢–£–†–ê")
    # ============================================================
    
    print("""
    –Ø–∫ node_class –ø–µ—Ä–µ–¥–∞—î—Ç—å—Å—è —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É:
    
    gc.crawl(node_class=CustomNode)
    ‚îî‚îÄ‚îÄ api/simple.py::crawl()
        ‚îî‚îÄ‚îÄ CrawlerConfig(custom_node_class=CustomNode)
            ‚îî‚îÄ‚îÄ GraphCrawlerClient.crawl()
                ‚îî‚îÄ‚îÄ GraphSpider(config)
                    ‚îî‚îÄ‚îÄ LinkProcessor(custom_node_class=CustomNode)
                        ‚îî‚îÄ‚îÄ process_links()
                            ‚îî‚îÄ‚îÄ target_node = CustomNode(url=link, ...)
                                ‚îî‚îÄ‚îÄ NodeScanner.scan_node(node)
                                    ‚îî‚îÄ‚îÄ node._update_from_context(context)
    
    –¢–æ–±—Ç–æ:
    1. CustomNode –ø–µ—Ä–µ–¥–∞—î—Ç—å—Å—è –≤ config
    2. LinkProcessor –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –π–æ–≥–æ –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö –Ω–æ–¥
    3. –ü—ñ—Å–ª—è –ø–∞—Ä—Å–∏–Ω–≥—É –≤–∏–∫–ª–∏–∫–∞—î—Ç—å—Å—è _update_from_context()
    """)
    
    print_section("–¢–ï–°–¢ 2 –ó–ê–í–ï–†–®–ï–ù–û")
    return graph


if __name__ == "__main__":
    print("\n" + "*" * 80)
    print("  GRAPHCRAWLER v3.0 - TRACING TEST 02: CUSTOM NODE")
    print("*" * 80)
    
    graph = asyncio.run(test_custom_node())
    
    print("\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
